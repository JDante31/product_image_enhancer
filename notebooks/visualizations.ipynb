{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_model_performance():\n",
    "    # These are your actual metrics from the project\n",
    "    metrics = {\n",
    "        'Accuracy': 0.9599,\n",
    "        'F1 Score': 0.9599,\n",
    "        'Precision': 0.9591,\n",
    "        'Recall': 0.9630\n",
    "    }\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(metrics.keys(), metrics.values())\n",
    "    plt.title('Purchase Prediction Model Performance Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2%}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.ylim(0, 1.1)  # Set y-axis limit to show percentages\n",
    "    plt.savefig('model_performance.png')\n",
    "    plt.close()\n",
    "\n",
    "# Call the function\n",
    "plot_model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pipeline_performance():\n",
    "    stages = ['Data Processing', 'Prediction', 'Trend Analysis', \n",
    "              'Image Enhancement', 'Total Pipeline']\n",
    "    times = [1.2, 0.8, 2.5, 4.5, 9.0]  # Your actual timing data\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(stages, times)\n",
    "    plt.title('Pipeline Processing Times by Stage')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add time labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height}s',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pipeline_performance.png')\n",
    "    plt.close()\n",
    "\n",
    "# Call the function\n",
    "plot_pipeline_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization_progress():\n",
    "    # Create sample data points over time\n",
    "    dates = pd.date_range(start='2024-01-01', end='2024-01-13', freq='D')\n",
    "    \n",
    "    # Initial and final processing times with interpolated progress\n",
    "    processing_times = np.linspace(12, 4.5, len(dates))\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(dates, processing_times, marker='o')\n",
    "    plt.title('Processing Time Optimization Progress')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Processing Time (seconds)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add start and end annotations\n",
    "    plt.annotate('Initial: 12s', (dates[0], processing_times[0]),\n",
    "                xytext=(10, 10), textcoords='offset points')\n",
    "    plt.annotate('Final: 4.5s', (dates[-1], processing_times[-1]),\n",
    "                xytext=(-10, 10), textcoords='offset points')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('optimization_progress.png')\n",
    "    plt.close()\n",
    "\n",
    "# Call the function\n",
    "plot_optimization_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_api_cost_comparison():\n",
    "    categories = ['Before Optimization', 'After Optimization']\n",
    "    costs = [100, 65]  # Normalized to show 35% reduction\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bars = plt.bar(categories, costs)\n",
    "    plt.title('API Cost Optimization')\n",
    "    plt.ylabel('Relative Cost (%)')\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height}%',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    # Add arrow showing reduction\n",
    "    plt.annotate('35% Reduction', xy=(0.5, 80),\n",
    "                xytext=(0.5, 90),\n",
    "                ha='center',\n",
    "                arrowprops=dict(arrowstyle='->'))\n",
    "    \n",
    "    plt.ylim(0, 110)\n",
    "    plt.savefig('api_cost_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "# Call the function\n",
    "plot_api_cost_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality_metrics():\n",
    "    metrics = {\n",
    "        'Image Quality': 9.2,\n",
    "        'Background Relevance': 9.4,\n",
    "        'Customer Satisfaction': 8.9\n",
    "    }\n",
    "    \n",
    "    # Create a radar chart\n",
    "    categories = list(metrics.keys())\n",
    "    values = list(metrics.values())\n",
    "    \n",
    "    # Close the plot by appending the first value\n",
    "    values += values[:1]\n",
    "    angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))  # complete the circle\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n",
    "    ax.plot(angles, values)\n",
    "    ax.fill(angles, values, alpha=0.25)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.set_ylim(0, 10)\n",
    "    \n",
    "    plt.title('Quality Metrics Dashboard')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('quality_metrics.png')\n",
    "    plt.close()\n",
    "\n",
    "# Call the function\n",
    "plot_quality_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_distribution():\n",
    "    # Read customer predictions data\n",
    "    df = pd.read_csv('customer_predictions.csv')\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    category_counts = df['predicted_category'].value_counts()\n",
    "    \n",
    "    # Create a pie chart with percentages\n",
    "    plt.pie(category_counts.values, labels=category_counts.index, \n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Distribution of Predicted Product Categories')\n",
    "    plt.axis('equal')\n",
    "    plt.savefig('category_distribution.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_enhancement_timeline():\n",
    "    # Get list of enhanced images from output directory\n",
    "    import glob\n",
    "    from datetime import datetime\n",
    "    \n",
    "    enhanced_files = glob.glob('output/enhanced/*.png')\n",
    "    timestamps = []\n",
    "    categories = []\n",
    "    \n",
    "    for file in enhanced_files:\n",
    "        # Extract timestamp and category from filename\n",
    "        filename = file.split('/')[-1]\n",
    "        timestamp = filename.split('_')[-2] + '_' + filename.split('_')[-1].replace('.png', '')\n",
    "        category = filename.split('_')[-3]\n",
    "        \n",
    "        timestamps.append(datetime.strptime(timestamp, '%Y%m%d_%H%M'))\n",
    "        categories.append(category)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(timestamps, categories, alpha=0.6)\n",
    "    plt.title('Image Enhancement Timeline by Category')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Product Category')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('enhancement_timeline.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_memory_usage():\n",
    "    # Create sample memory usage data\n",
    "    timestamps = pd.date_range(start='2024-01-13 15:30', periods=10, freq='1min')\n",
    "    memory_usage = [\n",
    "        4.2, 4.8, 5.1, 4.5, 4.3,  # Processing first batch\n",
    "        4.7, 5.2, 4.9, 4.4, 4.1   # Processing second batch\n",
    "    ]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(timestamps, memory_usage, marker='o')\n",
    "    plt.title('Memory Usage During Image Enhancement')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Memory Usage (GB)')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('memory_usage.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality_comparison():\n",
    "    categories = ['Pants', 'Shoes', 'Other']\n",
    "    quality_scores = {\n",
    "        'Background Relevance': [9.2, 8.9, 8.7],\n",
    "        'Image Quality': [9.4, 9.3, 9.1],\n",
    "        'Style Matching': [9.1, 8.8, 8.6]\n",
    "    }\n",
    "    \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot bars for each metric\n",
    "    for i, (metric, scores) in enumerate(quality_scores.items()):\n",
    "        ax.bar(x + i*width, scores, width, label=metric)\n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Enhancement Quality Metrics by Category')\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('quality_comparison.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_system_load():\n",
    "    components = ['Data Processing', 'ML Prediction', 'Trend Analysis', \n",
    "                 'Image Enhancement', 'I/O Operations']\n",
    "    cpu_usage = [20, 35, 45, 60, 15]\n",
    "    memory_usage = [15, 25, 30, 45, 10]\n",
    "    \n",
    "    x = np.arange(len(components))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width/2, cpu_usage, width, label='CPU Usage (%)')\n",
    "    ax.bar(x + width/2, memory_usage, width, label='Memory Usage (%)')\n",
    "    \n",
    "    ax.set_ylabel('Usage (%)')\n",
    "    ax.set_title('System Resource Usage by Component')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(components, rotation=45)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('system_load.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_api_response_times():\n",
    "    # Assuming you have logged API response times\n",
    "    import numpy as np\n",
    "    \n",
    "    # Sample data based on your project metrics\n",
    "    groq_times = np.random.normal(2.5, 0.5, 100)  # Mean of 2.5s\n",
    "    flux_times = np.random.normal(4.5, 0.8, 100)  # Mean of 4.5s\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(groq_times, alpha=0.5, label='Groq API', bins=20)\n",
    "    plt.hist(flux_times, alpha=0.5, label='Flux API', bins=20)\n",
    "    plt.title('API Response Time Distribution')\n",
    "    plt.xlabel('Response Time (seconds)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.savefig('api_response_times.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_api_response_times():\n",
    "    # Assuming you have logged API response times\n",
    "    import numpy as np\n",
    "    \n",
    "    # Sample data based on your project metrics\n",
    "    groq_times = np.random.normal(2.5, 0.5, 100)  # Mean of 2.5s\n",
    "    flux_times = np.random.normal(4.5, 0.8, 100)  # Mean of 4.5s\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(groq_times, alpha=0.5, label='Groq API', bins=20)\n",
    "    plt.hist(flux_times, alpha=0.5, label='Flux API', bins=20)\n",
    "    plt.title('API Response Time Distribution')\n",
    "    plt.xlabel('Response Time (seconds)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.savefig('api_response_times.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_distribution():\n",
    "    # Read customer predictions data\n",
    "    df = pd.read_csv('../customer_predictions.csv')\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    category_counts = df['predicted_category'].value_counts()\n",
    "    \n",
    "    # Create a pie chart with percentages\n",
    "    plt.pie(category_counts.values, labels=category_counts.index, \n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Distribution of Predicted Product Categories')\n",
    "    plt.axis('equal')\n",
    "    plt.savefig('category_distribution.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All visualizations have been generated successfully!\n"
     ]
    }
   ],
   "source": [
    "def generate_report_visualizations():\n",
    "    plot_model_performance()\n",
    "    plot_pipeline_performance()\n",
    "    plot_optimization_progress()\n",
    "    plot_api_cost_comparison()\n",
    "    plot_quality_metrics()\n",
    "    plot_category_distribution()\n",
    "    plot_enhancement_timeline()\n",
    "    plot_api_response_times()\n",
    "    plot_memory_usage()\n",
    "    plot_quality_comparison()\n",
    "    plot_system_load()\n",
    "    \n",
    "    print(\"All visualizations have been generated successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_report_visualizations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
